{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from moviepy.editor import VideoFileClip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import create_spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clip extraction\n",
    "\n",
    "*Given a start and end time (i.e. for a piece, movement - the smallest 'continuous' segment of music)* \\\n",
    "*Window = 10 sec*\n",
    "\n",
    "Method 1. Sliding window, no overlap \\\n",
    "Method 2. Sliding window, overlap (___ sec) \\\n",
    "Method 3. Random sampling (____ clips per ____ sec segment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "1. Videos are in 720p if possible, otherwise whatever's the highest i can get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_dir = \"data/\"\n",
    "filename = \"1234567.mp4\"\n",
    "vid = VideoFileClip(os.path.join(video_dir, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"data\"\n",
    "clip_dir = os.path.join(root_dir, \"clips\")\n",
    "audio_dir = os.path.join(root_dir, \"audio\")\n",
    "\n",
    "if not os.path.exists(clip_dir):\n",
    "    os.makedirs(clip_dir)\n",
    "\n",
    "if not os.path.exists(audio_dir):\n",
    "    os.makedirs(audio_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_fps = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segments so I don't forget\n",
    "\n",
    "Current total (approx): 7 hr 50 min\n",
    "\n",
    "Fast:\n",
    "1. La campanella: 0:05 to 4:25\n",
    "2. scarbo: 0:10 to 8:24\n",
    "3. \n",
    "\n",
    "Slow:\n",
    "1. tristesse: 0:05 to 4:10\n",
    "2. arabesque 1 (debussy): 0:00 to 4:21\n",
    "3. handel g minor minuet: 0:00 to 3:31\n",
    "4. \n",
    "\n",
    "bit of both:\n",
    "1. chopin ballade: 0:05 to 9:25\n",
    "2. hammerklavier (full): 0:00 to 10:32, 10:39 to 13:09, 13:15 to 28:45, 29:00 to 39:29\n",
    "3. goldberg variations (full): 0:05 to 1:23:22\n",
    "4. italian concerto (full): 0:11 to 3:52, 4:00 to 8:06, 8:51 to 11:54\n",
    "5. bach WTC book 1 (full): 0:24 to 2:05:15\n",
    "6. appassionata (full): 0:02 to 9:27, 9:37 to 22:47\n",
    "7. pathetique (full): 0:12 to 8:44, 9:04 to 13:40, 13:49 to 18:17\n",
    "8. waldstein (full): 0:53 to 9:10, 9:31 to 9:43, 10:24 to 12:00, 12:25 to 13:29, 14:12 to 23:45\n",
    "9. moonlight sonata (full): 0:46 to 9:02, 9:09 to 14:46\n",
    "10. pastoral sonata (full): 0:09 to 9:26, 9:35 to 16:16, 16:26 to 23:01\n",
    "11. mozart sonata 8 (full): 0:25 to 5:55, 6:13 to 15:38, 15:48 to 18:42\n",
    "12. mozart sonata 1 (full): 0:39 to 7:22, 7:33 to 14:50, 15:05 to 20:02\n",
    "13. mozart sonata 3 (full): 0:02 to 6:35, 6:41 to 13:41, 13:47 to 18:24\n",
    "14. mozart sonata 12 (full): 0:05 to 4:57, 5:15 to 9:48, 10:00 to 15:16\n",
    "15. mozart sonata 6 (full): 0:03 to 3:41, 3:48 to 9:39, 9:49 to 22:04\n",
    "16. mozart sonata 10 (full): 0:11 to 2:36, 2:56 to 4:43, 5:03 to 6:01, 6:14 to 11:38, 12:02 to 15:26\n",
    "17. \n",
    "\n",
    "AIM FOR 30 HOURS (a bit over 10k samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define segment of video to extract from\n",
    "start_sec = 0\n",
    "end_sec = 0\n",
    "\n",
    "dur = 10\n",
    "audio_subclip_dur = 2  # duration of audio subclips (for video llama) in seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = filename.split('.')[0]\n",
    "clip_counter = 0\n",
    "\n",
    "for i in range(start_sec, end_sec, dur):\n",
    "    \n",
    "    if (end_sec - i) < dur:\n",
    "        break\n",
    "\n",
    "    # save video clip\n",
    "    # NOTE: just saving the 10 sec clips\n",
    "        # the preprocessing in video llama repo extracts every n_frms frames\n",
    "        # ill try first with just every frame\n",
    "    clip = vid.subclip(i, i+dur)\n",
    "    clip.write_videofile(os.path.join(clip_dir, f'{fname}_{clip_counter}.mp4'), fps=30, audio=False)\n",
    "\n",
    "    # save audio clip\n",
    "    # NOTE: just saving the 10 sec clips\n",
    "        # the preprocessing in the video llama repo extracts consecutive audio subclips\n",
    "        # which i'll set to 5 subclips of 2 sec each (to span the entire audio clip)\n",
    "    clip_audio = clip.audio\n",
    "    clip_audio.write_audiofile(os.path.join(audio_dir, f'{fname}_{clip_counter}.wav'), fps=44100, codec=\"pcm_s16le\")\n",
    "    \n",
    "    '''for j in range(0, dur, audio_subclip_dur):\n",
    "\n",
    "        # save audio subclip as wav\n",
    "        audio_subclip = clip_audio.subclip(j, j+audio_subclip_dur)\n",
    "        audio_subclip_path = os.path.join(audio_dir, fname, str(clip_counter), str(int(j / audio_subclip_dur)) + \".wav\")\n",
    "        audio_subclip.write_audiofile(audio_subclip_path)\n",
    "\n",
    "        # extract and save spectrogram\n",
    "        create_spectrogram(audio_subclip_path)\n",
    "\n",
    "        # delete wav\n",
    "        os.remove(audio_subclip_path)'''\n",
    "\n",
    "    # extract, preprocess, and save frames\n",
    "    # TODO: optical flow, contouring?\n",
    "    '''frame_counter = 0\n",
    "    for frame in clip.iter_frames(fps=video_fps):\n",
    "        # frame is a H x W x N (N = 3 for RGB) np.array\n",
    "        frame_path = os.path.join(clip_vid_dir, str(frame_counter) + \".npy\")\n",
    "        np.save(frame_path, frame)\n",
    "        frame_counter += 1'''\n",
    "\n",
    "    clip_counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create csv for Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_prop = 0.1\n",
    "# ill get separate test data later (can be more isolated clips and such)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_paths = []\n",
    "audio_paths = []\n",
    "\n",
    "for file in os.listdir(clip_dir):\n",
    "    fname = file.split('.')[0]\n",
    "    if os.path.exists(os.path.join(audio_dir, f'{fname}.wav')):\n",
    "        clip_paths.append(os.path.join(clip_dir, file))\n",
    "        audio_paths.append(os.path.join(audio_dir, f'{fname}.wav'))\n",
    "    else:\n",
    "        print(f'No audio file for clip {file}')\n",
    "\n",
    "df = pd.DataFrame({'clip_path': clip_paths, 'audio_path': audio_paths})\n",
    "train_df = df.sample(frac=(1-val_prop), replace=False, random_state=0)\n",
    "val_df = df[~df['clip_path'].isin(train_df['clip_path'])]\n",
    "\n",
    "train_df.to_csv(os.path.join(root_dir, 'train_ds.csv'))\n",
    "val_df.to_csv(os.path.join(root_dir, 'val_ds.csv'))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
